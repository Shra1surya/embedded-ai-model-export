{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shra1surya/embedded-ai-model-export/blob/main/day2_day3_tflite_conversion_and_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86ccc419",
      "metadata": {
        "id": "86ccc419"
      },
      "source": [
        "# üì¶ ONNX ‚Üí TFLite Conversion and Deployment Simulation\n",
        "\n",
        "This notebook continues from the ONNX quantization project. It shows how to:\n",
        "- Convert a model from ONNX to TensorFlow (via ONNX-TF)\n",
        "- Convert TensorFlow model to TensorFlow Lite (TFLite)\n",
        "- Simulate inference with TFLite Interpreter\n",
        "- Compare size and latency\n",
        "\n",
        "‚úÖ This simulates embedded deployment without hardware."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade typeguard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hl9EzUerRYh",
        "outputId": "c335fd49-6920-422a-938e-4c885c95adde"
      },
      "id": "2hl9EzUerRYh",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.11/dist-packages (2.13.3)\n",
            "Collecting typeguard\n",
            "  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.14.0 in /usr/local/lib/python3.11/dist-packages (from typeguard) (4.14.1)\n",
            "Downloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
            "Installing collected packages: typeguard\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 2.13.3\n",
            "    Uninstalling typeguard-2.13.3:\n",
            "      Successfully uninstalled typeguard-2.13.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-addons 0.23.0 requires typeguard<3.0.0,>=2.7, but you have typeguard 4.4.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typeguard-4.4.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a64d891a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a64d891a",
        "outputId": "b4cc7ca7-046c-4caf-be15-c24d6a34783e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting onnx-tf\n",
            "  Downloading onnx_tf-1.10.0-py3-none-any.whl.metadata (510 bytes)\n",
            "Collecting tflite-runtime\n",
            "  Downloading tflite_runtime-2.14.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.14.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "INFO: pip is looking at multiple versions of tf2onnx to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.16.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading tf2onnx-1.15.1-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading tf2onnx-1.15.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading tf2onnx-1.14.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading tf2onnx-1.13.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading tf2onnx-1.12.1-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading tf2onnx-1.12.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "INFO: pip is still looking at multiple versions of tf2onnx to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading tf2onnx-1.11.1-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading tf2onnx-1.10.1-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading tf2onnx-1.9.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading tf2onnx-1.9.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading tf2onnx-1.9.1-py3-none-any.whl.metadata (1.2 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading tf2onnx-1.8.5-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading tf2onnx-1.8.4-py3-none-any.whl.metadata (390 bytes)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from onnx-tf) (6.0.2)\n",
            "Collecting tensorflow-addons (from onnx-tf)\n",
            "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->onnx-tf)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf2onnx-1.8.4-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m345.3/345.3 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tflite_runtime-2.14.0-cp311-cp311-manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tflite-runtime, onnx, tf2onnx, tensorflow-addons, onnx-tf\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.4\n",
            "    Uninstalling typeguard-4.4.4:\n",
            "      Successfully uninstalled typeguard-4.4.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.18.0 onnx-tf-1.10.0 tensorflow-addons-0.23.0 tf2onnx-1.8.4 tflite-runtime-2.14.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx tensorflow tf2onnx onnx-tf tflite-runtime\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install tflite-runtime || echo \"If this fails, we will use tf.lite.Interpreter from TensorFlow.\""
      ],
      "metadata": {
        "id": "v_oUUHi6obZy"
      },
      "id": "v_oUUHi6obZy",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f2PN8SGCrMDm"
      },
      "id": "f2PN8SGCrMDm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf, onnx, onnx_tf\n",
        "print(\"TF:\", tf.__version__)\n",
        "print(\"onnx:\", onnx.__version__)\n",
        "print(\"onnx-tf:\", onnx_tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "AwcBwKQNoyY7",
        "outputId": "93999689-46ab-43ce-87a9-bae4411e307b"
      },
      "id": "AwcBwKQNoyY7",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.19.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras.src.engine'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2074504542.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TF:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"onnx:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"onnx-tf:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnx_tf/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnx_tf/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_unique_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msupports_device\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcommon_supports_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandler_helper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_all_backend_handlers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpb_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOnnxNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_tf_module\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackendTFModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnx_tf/common/handler_helper.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_handler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackendHandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnx_tf/handlers/backend/hardmax.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_handler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackendHandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_addons/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Local project imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_addons/activations/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Additional activation functions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhardshrink\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhardshrink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisht\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlisht\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_addons/activations/gelu.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorLike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow_addons/utils/types.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# New versions of Keras require importing from `keras.src` when\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# importing internal symbols.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2.5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.src.engine'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Remove the thing causing the conflict\n",
        "!pip -q uninstall -y tensorflow-addons\n",
        "\n",
        "# 2) (Optional) sanity print of versions after removal\n",
        "import tensorflow as tf, onnx\n",
        "print(\"TF:\", tf.__version__)\n",
        "print(\"onnx:\", onnx.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIEAOlgPs5KJ",
        "outputId": "7e9c5348-241a-4f42-c1a7-ea07a235cd5f"
      },
      "id": "VIEAOlgPs5KJ",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF: 2.19.0\n",
            "onnx: 1.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Train ‚Üí Convert ‚Üí Infer (clean path)\n",
        "1) Train the TensorFlow model (1‚Äì2 epochs)\n",
        "\n",
        "Paste this into a new Colab cell (even if you already created model_tf, this will (re)create+train it):"
      ],
      "metadata": {
        "id": "2DDJuOGExuUm"
      },
      "id": "2DDJuOGExuUm"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load MNIST from Keras (already normalized after /255.0 below)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = (x_train.astype(\"float32\") / 255.0)[..., None]  # (N, 28, 28, 1)\n",
        "x_test  = (x_test.astype(\"float32\")  / 255.0)[..., None]\n",
        "\n",
        "# Define model (same topology as before)\n",
        "inputs = tf.keras.Input(shape=(28,28,1))\n",
        "x = tf.keras.layers.Conv2D(8, 3, activation='relu')(inputs)\n",
        "x = tf.keras.layers.MaxPool2D()(x)\n",
        "x = tf.keras.layers.Conv2D(16, 3, activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPool2D()(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(50, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(10)(x)  # logits\n",
        "model_tf = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile & train briefly\n",
        "model_tf.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model_tf.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=2, batch_size=128, validation_split=0.1, verbose=1\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model_tf.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"‚úÖ Test accuracy after training: {test_acc:.4f}\")\n",
        "\n",
        "# Save SavedModel for TFLite conversion\n",
        "model_tf.export(\"tf_model\")\n",
        "print(\"‚úÖ Saved trained TF model at ./tf_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9BSj-FCxv1c",
        "outputId": "5f724062-4b12-40f1-fc29-ae7460264529"
      },
      "id": "k9BSj-FCxv1c",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 45ms/step - accuracy: 0.7717 - loss: 0.8701 - val_accuracy: 0.9713 - val_loss: 0.1074\n",
            "Epoch 2/2\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - accuracy: 0.9649 - loss: 0.1195 - val_accuracy: 0.9785 - val_loss: 0.0788\n",
            "‚úÖ Test accuracy after training: 0.9734\n",
            "Saved artifact at 'tf_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='keras_tensor_41')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  134514170737680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134514170734032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134514170736528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134514170733840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134514170736720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134514170740368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134514170738640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134514170736336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "‚úÖ Saved trained TF model at ./tf_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Tiny TF CNN similar to PyTorch one\n",
        "inputs = tf.keras.Input(shape=(28,28,1))\n",
        "x = tf.keras.layers.Conv2D(8, 3, activation='relu')(inputs)\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\n",
        "x = tf.keras.layers.Conv2D(16, 3, activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(50, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(10)(x)\n",
        "model_tf = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model_tf.export(\"tf_model\")\n",
        "print(\"‚úÖ Fallback TF SavedModel created at ./tf_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2yZo3wJpQ3W",
        "outputId": "565e8d4e-ac8e-4ce0-82f4-126e96c28518"
      },
      "id": "i2yZo3wJpQ3W",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at 'tf_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='keras_tensor_25')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  134518221011088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134518317510160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134518317510928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134518277508752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134518277513168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134518317510736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134518277506832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  134518277509136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "‚úÖ Fallback TF SavedModel created at ./tf_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf, os\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"tf_model\")\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT] # size/latency hints\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"mnist_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "print(\" TFLite saved. Size:\", os.path.getsize(\"mnist_model.tflite\")/1024, \"KB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx55bt6stSvl",
        "outputId": "3b0ef8aa-e5e8-4dc9-cffe-118fa4f3322c"
      },
      "id": "Qx55bt6stSvl",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TFLite saved. Size: 27.1640625 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04068b1e",
      "metadata": {
        "id": "04068b1e"
      },
      "source": [
        "## üîé Run TFLite Inference\n",
        "\n",
        "Two ways to feed an image:\n",
        "\n",
        "A) Use Keras test image (matches the training preprocessing exactly)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, tensorflow as tf\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "# Load one test sample\n",
        "test_tf = transforms.ToTensor()\n",
        "mnist = MNIST(root='./data', train=False, download=True, transform=test_tf)\n",
        "img, label = mnist[0]\n",
        "x = img.unsqueeze(0).numpy().astype(np.float32)\n",
        "x = np.transpose(x, (0,2,3,1))\n",
        "\n",
        "# TFLite interpreter from TensorFlow\n",
        "interpreter = tf.lite.Interpreter(model_path=\"mnist_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "inp = interpreter.get_input_details()[0]['index']\n",
        "out = interpreter.get_output_details()[0]['index']\n",
        "\n",
        "# Pick a test sample\n",
        "idx = 0\n",
        "x = x_test[idx:idx+1].astype(np.float32)  # shape: (1,28,28,1)\n",
        "y = y_test[idx]\n",
        "\n",
        "interpreter.set_tensor(inp, x)\n",
        "interpreter.invoke()\n",
        "logits = interpreter.get_tensor(out)\n",
        "pred = np.argmax(logits)\n",
        "print(f\"‚úÖ TFLite Prediction: {pred} | Label: {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Akb9JEjMuZbB",
        "outputId": "7e3f64e0-f1b5-45cd-f646-0480fef45ec5"
      },
      "id": "Akb9JEjMuZbB",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ TFLite Prediction: 7 | Label: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "B) Or use the torchvision sample (ensure NHWC + float32 in [0,1])"
      ],
      "metadata": {
        "id": "yfHU4rZgy7Cf"
      },
      "id": "yfHU4rZgy7Cf"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, tensorflow as tf\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "test_tf = transforms.ToTensor()  # returns float32 in [0,1]\n",
        "mnist = MNIST(root=\"./data\", train=False, download=True, transform=test_tf)\n",
        "img, label = mnist[0]                           # tensor [1,28,28]\n",
        "x = img.unsqueeze(0).numpy().astype(np.float32) # [1,1,28,28]\n",
        "x = np.transpose(x, (0,2,3,1))                  # ‚Üí [1,28,28,1] NHWC\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=\"mnist_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "inp = interpreter.get_input_details()[0]['index']\n",
        "out = interpreter.get_output_details()[0]['index']\n",
        "\n",
        "interpreter.set_tensor(inp, x)\n",
        "interpreter.invoke()\n",
        "logits = interpreter.get_tensor(out)\n",
        "pred = np.argmax(logits)\n",
        "print(f\"‚úÖ TFLite Prediction: {pred} | Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIUgWZS9y_w_",
        "outputId": "472d196e-42b8-44f6-95eb-f9abca7393a0"
      },
      "id": "IIUgWZS9y_w_",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ TFLite Prediction: 7 | Label: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should now see the prediction match the label most of the time."
      ],
      "metadata": {
        "id": "K8pBHOmOzFbC"
      },
      "id": "K8pBHOmOzFbC"
    },
    {
      "cell_type": "markdown",
      "id": "fc5af3b1",
      "metadata": {
        "id": "fc5af3b1"
      },
      "source": [
        "## ‚è±Ô∏è Benchmark TFLite Inference Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "85effc01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85effc01",
        "outputId": "bbbbbe7f-ad8e-48b8-fb87-c75124410e88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Average inference time (TFLite): 0.025 ms\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "def benchmark_tflite(interpreter, x, runs=100):\n",
        "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "    start = time.time()\n",
        "    for _ in range(runs):\n",
        "        interpreter.set_tensor(input_index, x)\n",
        "        interpreter.invoke()\n",
        "        _ = interpreter.get_tensor(output_index)\n",
        "    end = time.time()\n",
        "    return (end - start) * 1000 / runs\n",
        "\n",
        "avg_time = benchmark_tflite(interpreter, x)\n",
        "print(f\"üìä Average inference time (TFLite): {avg_time:.3f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Optional) FP16 TFLite for smaller file"
      ],
      "metadata": {
        "id": "8s2j9Zj3wKo1"
      },
      "id": "8s2j9Zj3wKo1"
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"tf_model\")\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]  # weights to FP16\n",
        "tflite_fp16 = converter.convert()\n",
        "open(\"mnist_model_fp16.tflite\", \"wb\").write(tflite_fp16)\n",
        "\n",
        "import os\n",
        "print(\"‚úÖ FP16 TFLite saved. Size:\", os.path.getsize(\"mnist_model_fp16.tflite\")/1024, \"KB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zV1FveVHwQwn",
        "outputId": "4bb11152-7e39-41ba-a420-2975d1fb3d96"
      },
      "id": "zV1FveVHwQwn",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ FP16 TFLite saved. Size: 46.78125 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l mnist_model*\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJvpmQZswg6-",
        "outputId": "ef0f1d4f-347b-4d41-b11a-42372b88a9d3"
      },
      "id": "wJvpmQZswg6-",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 47116 Aug  8 22:16 mnist_model_fp16.tflite\n",
            "-rw-r--r-- 1 root root 27248 Aug  8 22:05 mnist_model.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "002ee51f",
      "metadata": {
        "id": "002ee51f"
      },
      "source": [
        "## üìò Summary\n",
        "\n",
        "- ONNX ‚Üí TensorFlow conversion succeeded\n",
        "- TensorFlow ‚Üí TFLite conversion succeeded\n",
        "- TFLite inference gave correct prediction\n",
        "- Inference time benchmarked\n",
        "\n",
        "This simulation is useful for embedded developers targeting TFLite Micro or ARM ML SDKs."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}